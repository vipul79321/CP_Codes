[Link](https://www2.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/8_MainMemory.html)

---

**NOTE** - [Copy-on-write Forking](https://www.geeksforgeeks.org/copy-on-write/)
* The idea behind a copy-on-write is that when a parent process creates a child process then both of these processes initially will share the same pages in memory.
* These shared pages will be marked as copy-on-write.
* Now if any of these processes will try to modify the shared pages then only a copy of these pages will be created and the modifications will be done on the copy of pages by that process and thus not affecting the other process.
---

**NOTE** - In decreasing order of **access speed**
* Registers
* Cache
* Main Memory
* Secondary Memory(Hard-drive)
---

### Address Binding
[Link](https://www.geeksforgeeks.org/memory-allocation-techniques-mapping-virtual-addresses-to-physical-addresses/)
* Address binding is the process of mapping from **logical** address space to **physical** address space.
* There are three types of address binding - 
  * **Compile Time** 
    * If you know that during compile time, where process will reside in memory, then an absolute address is generated. i.e the physical address is embedded to the executable of the program during compilation.
    * Loading the executable as a process in memory is very fast.
    * But if program is relocated then it has to be **recompiled**
  * **Load Time**
    * If the location at which a program will be loaded is not known at compile time, then the compiler must generate relocatable code with reference relative to address of start of program
    * If that address changes then program must be **reloaded**
    * The loader translates the relocatable address to an absolute address
  * **Execution Time** 
    * If a program can be moved around in memory during the course of its execution, then binding must be delayed until execution time.
    * This requires special hardware, and is the method implemented by most modern OSes.
    * E.g - this technique is used in compaction

![Multi-step processing of user program](https://github.com/vipul79321/CP_Codes/blob/main/images/multistep-processing-of-user-program.jpg)

---

### Logical and Physical Address
[Link](https://www.geeksforgeeks.org/logical-and-physical-address-in-operating-system/)

* **Logical Address** - The address generated by the CPU is a logical address. It is also known as **virtual address**
* **Physical Address** - The address actually seen by the memory hardware is a physical address.
* **Logical Address Space** - The set of all logical addresses used by a program composes the logical address space
* **Physical Address Space** - The set of all corresponding physical addresses composes the physical address space.

**NOTE** - 
* Addresses bound at compile time or load time have **identical** logical and physical addresses.
* Addresses created at execution time, however, have different logical and physical addresses
* Mapping of logical address to corresponding physical address is done by **Memory Management Unit**
* **Relocation Register** - Used as reference for logical address to generate relocatable code 
* **Limit Register** - Used as limit to prevent illegal memory access. All access should be range `[Relocation Register, Relocation Register + Limit Register]`

---

### Dynamic Loading

* Rather than loading an entire program into memory at once, dynamic loading loads up each routine as it is called. 
* The advantage is that unused routines need never be loaded, reducing total memory usage and generating faster program startup times. 
* The downside is the added complexity and overhead of checking to see if a routine is loaded every time it is called and then then loading it up if it is not already loaded.

---

### Static Linking vs Dynamic Linking
[Link](https://www.geeksforgeeks.org/static-and-dynamic-linking-in-operating-systems/)

* **Static Linking**
  * With static linking library modules get fully included in executable modules.
  * _Disadvantages_ -
    * It wastes both disk space and main memory usage because every program that included a certain routine from the library would have to have their own copy of that routine linked into their executable code.
    * Whenever a library routine updates then the program must be re-built ( re-linked ) in order to incorporate the changes.

* **Dynamic Linking** - 
  * With dynamic linking, however, only a stub(a statically linked function) is linked into the executable module, containing references to the actual library module linked in at run time.
  * _Advantages_
    * Saves memory
    * Easy to share - If the code section of library routine is reentrant then we can only load one copy of dynamically linked routines into memory and sharing the code amongst all processes
    * Library routines are updated then we dont need to rebuild as long as stub remains the same. The program can be updated merely by loading new versions of the DLLs onto the system

---
**NOTE** - If compile-time or load-time address binding is used, then processes must be swapped back into the same memory location from which they were swapped out. If execution time binding is used, then the processes can be swapped back into any available location.

---

### Contiguous Memory Allocation

* Contiguous memory allocation allocates consecutive blocks of memory to a file/process.
* Contiguous memory allocation can be categorized into two ways :
  * [Fixed partition scheme](https://www.geeksforgeeks.org/fixed-or-static-partitioning-in-operating-system/)
    * The number of partition of RAM is fixed, size of partition may or may not be same
    * _Advantages_
      * Easy to implement
    * _Disadvantages_
      * Internal Fragmentation
      * External Fragmentation
      * Restriction of maximum process size and degree of multiprogramming
  * [Variable partition scheme](https://www.geeksforgeeks.org/variable-or-dynamic-partitioning-in-operating-system/)
    * Intially RAM is empty and partition are made during runtime according to process's need
    * Therefore, Number of partitions in RAM is not fixed and depends on the number of incoming process and Main Memoryâ€™s size.
    * _Advantages_
      * No Internal Fragmentation - As partition are made depending on the process size itself at runtime
      * No restriction on maximum process size and degree of multiprogramming
    * _Disadvantages_ 
      * Difficult Implementation
      * External Fragmentation - As when a processes leaves they creates a hole equal to its size   

**Different Contiguous Memory Allocation Strategies** - 
* **First Fit** - Searches the first available hole from beginning, that is big enough to accomodate the process
* **Next Fit** - Searches the first available hole from where it last left-off, that is big enough to accomodate the process
* **Best Fit** - Searches smallest available hole that is big enough to accomodate the process
* **Worst Fit** - Assign largest available hole, if it can accomodate the process

**Few Important Points** - 
* Next fit and First fit are generally faster than other strategies while next fit being slightly more faster
* First fit tends to create more internal fragmentation in the begining, while next fit overcomes it by looking from the position is last left-off
* Simulations show that either first or best fit are better than worst fit in terms of both time and storage utilization.
* Best fit tends to create more internal fragmentation as leftover space is very small
* In worst fit, leftover space is large so it may be used by other smaller process


[Fragmentation](https://www.geeksforgeeks.org/difference-between-internal-and-external-fragmentation/)

**Internal Fragmentation**
* It happens when we allocate process to fixed size block. It may happen that block size is greater than what is required by process and this wasted space results in internal fragmentation
* Internal fragmentation can be avoided by dynamic allocation

**External Fragmentation**
* External fragmentation means that the available memory is broken up into lots of little pieces, none of which is big enough to satisfy the next memory requirement, although the sum total could.
* It can be overcome using paging or compaction

**Compaction** 
* External Fragmentation can be solved using compaction, given that all the programs  in memory are relocatable, then we can move all process down to one end of physical memory
* This only involves updating the relocation register for each process, as all internal work is done using logical addresses.


**Difference between Contiguous and Non-Contiguous Memory Allocation**

[Link](https://www.geeksforgeeks.org/difference-between-contiguous-and-noncontiguous-memory-allocation/)

| Contiguous Memory Allocation	| Non-Contiguous Memory Allocation |
| ----------------------------- | -------------------------------- |
| Contiguous memory allocation allocates consecutive blocks of memory to a file/process. |	Non-Contiguous memory allocation allocates separate blocks of memory to a file/process. |
| Faster and easier to implement.	| Slower and difficult to implement. |
| Overhead is minimum as not much address translations are there while executing a process.	| More Overheads are there as there are more address translations. |
| Wastage of memory is there. |	No memory wastage is there. |

---

